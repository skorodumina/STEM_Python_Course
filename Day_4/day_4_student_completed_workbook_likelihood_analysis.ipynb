{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import corner\n",
    "import nestle\n",
    "import pandas\n",
    "import warnings\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "import Library_GraphTwoDimensionDensityColorMap\n",
    "#---------------------------------------------------------------------\n",
    "warnings.simplefilter('ignore')\n",
    "print (\"done importing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the theorist give you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both data set cases:\n",
    "def my_model( v, g, t):\n",
    "    return v*t -.5*g*t**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1--Height Error Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the experimentalist give you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a perfect stopwatch, but not so perfect meter stick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(YOU NEED THIS CODE)\n",
    "#The experimentalist has a perfect stopwatch,\n",
    "#    and knows his height measurement error\n",
    "\n",
    "# Read in a file using astropy called \"1D_Generated_Data.astropydat\"\n",
    "\n",
    "data_with_height_error_only = pandas.read_csv( \"1D_Generated_Data.dat\" ,sep=' ',header=0)\n",
    "height_standard_deviation = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These should run without error\n",
    "assert data_with_height_error_only['time'][0] == .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the instrument error function of height\n",
    "Points = numpy.linspace(-50, 50, 100)\n",
    "Values = scipy.stats.norm.pdf(Points, 0, 10)\n",
    "plt.plot(Points,  Values, )\n",
    "plt.title(\"Probability Density Result of Measuring Zero\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the 1D-error data\n",
    "times_1d = data_with_height_error_only['time']\n",
    "heights_1d = data_with_height_error_only['height']\n",
    "plt.errorbar( times_1d, heights_1d, yerr = [height_standard_deviation]*len(times_1d) , fmt = \".\")\n",
    "plt.ylabel('Height (Meters)',fontsize=14)\n",
    "plt.xlabel('Time (Seconds)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct single datapoint likelihood function?\n",
    "###  \"Likelihood function\" fixes the observation values and allows the parameters to vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_single_measurement_1D(\n",
    "    observed_time, \n",
    "    observed_height,\n",
    "    v,\n",
    "    g,\n",
    "    ):\n",
    "\n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    #If we assume a velocity and gravitational constant\n",
    "    #    What height should we observe? \n",
    "    #    (students do this)\n",
    "    assume_model_is_correct_height = my_model(v, g, t = observed_time )\n",
    "    \n",
    "    #    What is the probability of a measuring an observed height and observed time?\n",
    "    #    (students do this)\n",
    "    def gaussian_centered_on_model( possible_height_measurement ):\n",
    "        #Create a 1D Gaussian with a mean=assume_model_is_correct_height,\n",
    "        #sigma=height_standard_deviation, which returns a probability for a \n",
    "        #given possible_height_measurement\n",
    "        result = scipy.stats.norm.pdf(\n",
    "            possible_height_measurement, \n",
    "            loc = assume_model_is_correct_height, \n",
    "            scale = height_standard_deviation)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    #Return the associated probability by plugging in the observed height:\n",
    "    likelihood_value = gaussian_centered_on_model( \n",
    "        possible_height_measurement = observed_height\n",
    "        )\n",
    "    #\n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    \n",
    "    \n",
    "    return(likelihood_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the correct number in the 1D-height-error-only case:\n",
    "print( probability_of_single_measurement_1D (\n",
    "    times_1d[0],\n",
    "    heights_1d[0],\n",
    "    v = 100,\n",
    "    g = 20\n",
    "    ) )\n",
    "#Expected result: 0.017829561071290335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(provided by instructors below):\n",
    "def generate_single_data_point_likelihood_function(\n",
    "    observed_time,\n",
    "    observed_height,\n",
    "    probability_of_single_measurement_function,\n",
    "    ):\n",
    "    def single_data_point_likelihood_function(\n",
    "        vg_vector, \n",
    "        ):\n",
    "        v = vg_vector[0]\n",
    "        g = vg_vector[1]\n",
    "        likelihood_value = probability_of_single_measurement_function(\n",
    "            observed_time = observed_time,\n",
    "            observed_height= observed_height,\n",
    "            v = v,\n",
    "            g = g,\n",
    "            )\n",
    "        return likelihood_value\n",
    "    \n",
    "    return single_data_point_likelihood_function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the height-only error case:\n",
    "likelihood_function_for_first_datapoint1d = generate_single_data_point_likelihood_function(\n",
    "    observed_time = times_1d[0],\n",
    "    observed_height = heights_1d[0],\n",
    "    probability_of_single_measurement_function = probability_of_single_measurement_1D,\n",
    "    )\n",
    "print ( likelihood_function_for_first_datapoint1d(  [100, 20]) )\n",
    "#Expected result: likelihood_fn(100, 20) == 0.017829561071290335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the all-data log-likelihood function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(provided below by instructors)\n",
    "#numpyize the data:\n",
    "#    Each row of the datapoints is a datapoint\n",
    "datapoints1d = numpy.vstack([times_1d, heights_1d]).T\n",
    "\n",
    "#    Looks like:\n",
    "#   [\n",
    "#   [time0, height0 ],\n",
    "#   [time1, height1 ],\n",
    "#   ...\n",
    "#   [timeN, heightN ],\n",
    "#   ]\n",
    "#\n",
    "\n",
    "def generate_log_likelihood_function_fixing_all_observations(\n",
    "        datapoints = None, \n",
    "        probability_of_single_measurement_function = None,\n",
    "        ):    \n",
    "    #Make a list where each element is a single-datapoint likelihood function\n",
    "    single_datapoint_likelihood_function_list = []\n",
    "    for datapoint in datapoints:\n",
    "        single_datapoint_likelihood_function = generate_single_data_point_likelihood_function(\n",
    "            observed_time = datapoint[0],\n",
    "            observed_height = datapoint[1],\n",
    "            probability_of_single_measurement_function = probability_of_single_measurement_function,\n",
    "            )\n",
    "        single_datapoint_likelihood_function_list.append( single_datapoint_likelihood_function )\n",
    "\n",
    "    #Define a log-likelihood funciton for all the data using the list defined above:\n",
    "    def log_likelihood_function_fixing_all_observations(parameters):\n",
    "        result = 0\n",
    "        for single_datapoint_likelihood_function in single_datapoint_likelihood_function_list:\n",
    "            result += numpy.log( single_datapoint_likelihood_function(parameters) )\n",
    "        return result\n",
    "            \n",
    "    return log_likelihood_function_fixing_all_observations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood_alldata_1d = generate_log_likelihood_function_fixing_all_observations(\n",
    "    datapoints = datapoints1d,\n",
    "    probability_of_single_measurement_function = probability_of_single_measurement_1D,\n",
    "    )\n",
    "loglikelihood_alldata_1d( numpy.array([40, 10]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the posterior using MCMC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the required functions for the mcmc tools:\n",
    "def bounds_to_ppf(bounds):\n",
    "    ppfs={}\n",
    "    for key in bounds.keys():\n",
    "        ppfs[key] = scipy.interpolate.interp1d([0.,1.],bounds[key])\n",
    "    return ppfs\n",
    "\n",
    "def prior_transform(nested_parameters):\n",
    "        actual_parameters = numpy.empty(n_varied_parameter_dim, dtype=numpy.float)\n",
    "        for i in range(n_varied_parameter_dim):\n",
    "            actual_parameters[i] = ppfs[varied_param_names[i]](nested_parameters[i])\n",
    "        return actual_parameters\n",
    "\n",
    "varied_param_names = ['v','g']\n",
    "parameter_bounds={'v':(0,100),'g':(0,20)}\n",
    "n_varied_parameter_dim = len(varied_param_names) \n",
    "ppfs=bounds_to_ppf(parameter_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_result1d = nestle.sample(\n",
    "    loglikelihood_alldata_1d, \n",
    "    prior_transform, \n",
    "    n_varied_parameter_dim,\n",
    "    npoints=100, \n",
    "    maxiter=None,\n",
    "    maxcall=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vparameters1d, cov1d = nestle.mean_and_cov(sample_result1d.samples, sample_result1d.weights)\n",
    "print('Best fit:', varied_param_names, '\\n',vparameters1d)\n",
    "print('Covariance:',varied_param_names, '\\n', cov1d)\n",
    "fig = corner.corner(\n",
    "    sample_result1d.samples, \n",
    "    labels=[\"$v$\", \"$g$\"],\n",
    "    quantiles=(0.16, 0.84),\n",
    "    levels=(1-numpy.exp(-0.5),),\n",
    "    truths=[v, g]\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE2: JOINT HEIGHT AND TIME ERROR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(YOU NEED THIS CODE)\n",
    "#The experimentalist knows \n",
    "#    his joint time, and height measurement error\n",
    "\n",
    "#DATA:\n",
    "data_with_heights_and_times_error = astropy.io.ascii.read( \"2D_Generated_Data.astropydat\" )\n",
    "times_2d = data_with_heights_and_times_error['time']\n",
    "heights_2d = data_with_heights_and_times_error['height']\n",
    "\n",
    "#ERROR:\n",
    "covariance_matrix = numpy.array(\n",
    "    [\n",
    "        [.58,   13.35],\n",
    "        [13.35, 501.77]\n",
    "    ])\n",
    "covariance_matrix_list = [covariance_matrix]*len(times_2d)\n",
    "\n",
    "def generate_experiment_error_function(mu, cov):\n",
    "    def experiment_error_function(Point):\n",
    "        x = Point\n",
    "        return scipy.stats.multivariate_normal.pdf(x, mu, cov)\n",
    "    return experiment_error_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTS (YOU DONT NEED THIS CODE)\n",
    "#    (You dont need this code but its here for illustration):\n",
    "#Make a quick plot of the experimentalist lab testing of his camera:\n",
    "experiment_error_function = generate_experiment_error_function(\n",
    "    numpy.array([0,0]), \n",
    "    covariance_matrix)\n",
    "Library_GraphTwoDimensionDensityColorMap.Main(\n",
    "    Function = experiment_error_function,\n",
    "    DomainMinimumPoint  = numpy.array([-2, -40]),\n",
    "    DomainMaximumPoint  = numpy.array([2, 40]),\n",
    "    ShowContours = True,\n",
    "    PrintExtra = False,\n",
    "    )\n",
    "plt.title(\"Probability Density Result of Measuring (t=0, h=0)\", fontsize=40)\n",
    "plt.ylabel('Height (Meters)',fontsize=40)\n",
    "plt.xlabel('Time (Seconds)',fontsize=40)\n",
    "plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTS  (YOU DONT NEED THIS CODE)\n",
    "#Plot the data:\n",
    "plt.scatter(times_2d,heights_2d)\n",
    "for i in range(len(times_2d)):\n",
    "    np=numpy\n",
    "    mu = np.array([times_2d[i],heights_2d[i]])\n",
    "    cov = covariance_matrix\n",
    "    Function = generate_experiment_error_function(mu, cov)\n",
    "    xmin=-3*np.sqrt(covariance_matrix[0][0])+times_2d[i]\n",
    "    xmax=3*np.sqrt(covariance_matrix[0][0])+times_2d[i]\n",
    "    ymin=-3*np.sqrt(covariance_matrix[1][1])+heights_2d[i]\n",
    "    ymax=3*np.sqrt(covariance_matrix[1][1])+heights_2d[i]\n",
    "    X, Y = numpy.mgrid[xmin:xmax:50j, ymin:ymax:50j] #1000 x 1000 -> 1 million points\n",
    "    PointsToPlugIn = numpy.vstack([X.ravel(), Y.ravel()])\n",
    "    PointsToPlugInDataset = PointsToPlugIn.T\n",
    "    PlugInPointsCount = len(PointsToPlugInDataset)\n",
    "    FunctionResultValuesForGrid = numpy.zeros((PlugInPointsCount))\n",
    "    k = 0\n",
    "    while (k < PlugInPointsCount):\n",
    "        PointToPlugIn = PointsToPlugInDataset[k]\n",
    "        FunctionValueForPointToPlugIn = Function(PointToPlugIn)\n",
    "        FunctionResultValuesForGrid[k] = FunctionValueForPointToPlugIn\n",
    "        k = k + 1\n",
    "    Z = numpy.reshape(FunctionResultValuesForGrid, X.shape)\n",
    "    CS = plt.contour(X, Y, Z, 2,\n",
    "                             colors='k', # negative contours will be dashed by default\n",
    "                             )\n",
    "plt.xlabel('Time (Seconds)',fontsize=14)\n",
    "plt.ylabel('Height (Meters)',fontsize=14)\n",
    "plt.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct single datapoint likelihood function?\n",
    "###  \"Likelihood function\" fixes the observation values and allows the parameters to vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_single_measurement_2D(\n",
    "    observed_time, \n",
    "    observed_height,\n",
    "    v,\n",
    "    g,\n",
    "    ):\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    #If we assume a velocity and gravitational constant\n",
    "    #    What height should we observe? \n",
    "    #    (students do this)\n",
    "    observed_timeheight_vector = numpy.array([observed_time, observed_height])   \n",
    "\n",
    "    #    What is the probability of a measuring an observed height and observed time?\n",
    "    #    (students do this)\n",
    "    def kernel_density_estimation_centered_on_model2d( possible_timeheight_vector ):\n",
    "        result = 0\n",
    "        kernel_count = 20\n",
    "        for t in numpy.linspace(0, 10, kernel_count):\n",
    "            \n",
    "            assume_model_is_correct_time_choice = t\n",
    "            assume_model_is_correct_height = my_model(v, g, t = assume_model_is_correct_time_choice )\n",
    "            assume_model_is_correct_mu = numpy.array(\n",
    "                [\n",
    "                assume_model_is_correct_time_choice, \n",
    "                assume_model_is_correct_height\n",
    "                ])\n",
    "\n",
    "            #print ('observed_timeheight_vector', observed_timeheight_vector)\n",
    "            #print ('assume_model_is_correct_mu', assume_model_is_correct_mu)\n",
    "            #print ('covariance_matrix', covariance_matrix)\n",
    "            \n",
    "            result += scipy.stats.multivariate_normal.pdf(\n",
    "                possible_timeheight_vector,\n",
    "                assume_model_is_correct_mu,\n",
    "                covariance_matrix, \n",
    "                )\n",
    "            #print ('probability', result)\n",
    "            \n",
    "        return result/ kernel_count\n",
    "\n",
    "    #Return the associated probability by plugging in the observed height:\n",
    "    likelihood_value = kernel_density_estimation_centered_on_model2d( \n",
    "        possible_timeheight_vector = observed_timeheight_vector\n",
    "        )\n",
    "    #\n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    \n",
    "    \n",
    "    return(likelihood_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the joint-time-height-error-case\n",
    "likelihood_function_for_first_datapoint2d = generate_single_data_point_likelihood_function(\n",
    "    observed_time = times_1d[0],\n",
    "    observed_height = heights_1d[0],\n",
    "    probability_of_single_measurement_function = probability_of_single_measurement_2D,\n",
    "    )\n",
    "print ( likelihood_function_for_first_datapoint2d( [100, 20] ) )\n",
    "#Expected result: likelihood_fn(100, 20) ==  0.0005510152162280714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the all-data log-likelihood function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(provided below by instructors)\n",
    "#numpyize the data:\n",
    "#    Each row of the datapoints is a datapoint\n",
    "datapoints2d = numpy.vstack([times_2d, heights_2d]).T\n",
    "#    Looks like:\n",
    "#   [\n",
    "#   [time0, height0 ],\n",
    "#   [time1, height1 ],\n",
    "#   ...\n",
    "#   [timeN, heightN ],\n",
    "#   ]\n",
    "#\n",
    "\n",
    "def generate_log_likelihood_function_fixing_all_observations(\n",
    "        datapoints = None, \n",
    "        probability_of_single_measurement_function = None,\n",
    "        ):    \n",
    "    #Make a list where each element is a single-datapoint likelihood function\n",
    "    single_datapoint_likelihood_function_list = []\n",
    "    for datapoint in datapoints:\n",
    "        single_datapoint_likelihood_function = generate_single_data_point_likelihood_function(\n",
    "            observed_time = datapoint[0],\n",
    "            observed_height = datapoint[1],\n",
    "            probability_of_single_measurement_function = probability_of_single_measurement_function,\n",
    "            )\n",
    "        single_datapoint_likelihood_function_list.append( single_datapoint_likelihood_function )\n",
    "\n",
    "    #Define a log-likelihood funciton for all the data using the list defined above:\n",
    "    def log_likelihood_function_fixing_all_observations(parameters):\n",
    "        result = 0\n",
    "        for single_datapoint_likelihood_function in single_datapoint_likelihood_function_list:\n",
    "            result += numpy.log( single_datapoint_likelihood_function(parameters) )\n",
    "        return result\n",
    "            \n",
    "    return log_likelihood_function_fixing_all_observations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood_alldata_2d = generate_log_likelihood_function_fixing_all_observations(\n",
    "    datapoints = datapoints1d,\n",
    "    probability_of_single_measurement_function = probability_of_single_measurement_2D,\n",
    "    )\n",
    "\n",
    "loglikelihood_alldata_2d( numpy.array([40, 10]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the posterior using MCMC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the required functions for the mcmc tools:\n",
    "def bounds_to_ppf(bounds):\n",
    "    ppfs={}\n",
    "    for key in bounds.keys():\n",
    "        ppfs[key] = scipy.interpolate.interp1d([0.,1.],bounds[key])\n",
    "    return ppfs\n",
    "\n",
    "def prior_transform(nested_parameters):\n",
    "        actual_parameters = np.empty(n_varied_parameter_dim, dtype=np.float)\n",
    "        for i in range(n_varied_parameter_dim):\n",
    "            actual_parameters[i] = ppfs[varied_param_names[i]](nested_parameters[i])\n",
    "        return actual_parameters\n",
    "\n",
    "varied_param_names = ['v','g']\n",
    "parameter_bounds={'v':(0,100),'g':(0,20)}\n",
    "n_varied_parameter_dim = len(varied_param_names) \n",
    "ppfs=bounds_to_ppf(parameter_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With an instrument which measures time and space at the same time with error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JOINT HEIGHT AND TIME ERROR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_result2d = nestle.sample(\n",
    "    loglikelihood_alldata_2d, \n",
    "    prior_transform, \n",
    "    n_varied_parameter_dim,\n",
    "    npoints=100, \n",
    "    maxiter=None,\n",
    "    maxcall=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vparameters2d, cov2d = nestle.mean_and_cov(sample_result2d.samples, sample_result2d.weights)\n",
    "print('Best fit:',    varied_param_names, '\\n',vparameters2d)\n",
    "print('Covariance:',  varied_param_names, '\\n', cov2d)\n",
    "fig = corner.corner(\n",
    "    sample_result2d.samples, \n",
    "    labels=[\"$v$\", \"$g$\"],\n",
    "    quantiles=(0.16, 0.84),\n",
    "    levels=(1-np.exp(-0.5),),\n",
    "    #truths=[v, g]\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets make the plot even nicer looking for the sake of illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = sample_result2d.samples\n",
    "kernel2d = scipy.stats.gaussian_kde( values.T ) #takes in points sideways....\n",
    "Library_GraphTwoDimensionDensityColorMap.Main(\n",
    "    Function = kernel2d.pdf,\n",
    "    DomainMinimumPoint  = numpy.array([40, 5]),\n",
    "    DomainMaximumPoint  = numpy.array([65, 15]),\n",
    "    ShowContours = True,\n",
    "    PrintExtra = False,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel2d_v_marginal = scipy.stats.gaussian_kde( values.T[0] ) \n",
    "Points = numpy.linspace(30, 90, 100)\n",
    "Values = kernel2d_v_marginal.pdf(Points)\n",
    "plt.plot(Points,  Values, )\n",
    "plt.ylabel( \"probability\",fontsize = 14 )\n",
    "plt.xlabel( \"$v$\",fontsize = 14 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel2d_g_marginal = scipy.stats.gaussian_kde( values.T[1] ) \n",
    "Points = numpy.linspace(0, 20, 100)\n",
    "Values = kernel2d_g_marginal.pdf(Points)\n",
    "plt.plot(Points,  Values, )\n",
    "plt.ylabel( \"probability\",fontsize = 14 )\n",
    "plt.xlabel( \"$g$\",fontsize = 14 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
